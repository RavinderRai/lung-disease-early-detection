{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Here we'll build a computer vision model to detect if a lung disease is present or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Using the final results from the data_exploration_and_processing notebook, we'll load our data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_image_files(index_lst: list):\n",
    "    image_files = []\n",
    "\n",
    "    for i in index_lst:\n",
    "        image_dir = f\"D:\\BigData\\images_00{i}\\images\"\n",
    "        \n",
    "        image_files_for_one_folder = os.listdir(image_dir)\n",
    "        \n",
    "        image_files += image_files_for_one_folder\n",
    "        \n",
    "    return image_files\n",
    "    \n",
    "image_files = get_image_files([1])\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_index</th>\n",
       "      <th>follow-up_#</th>\n",
       "      <th>patient_age</th>\n",
       "      <th>patient_gender</th>\n",
       "      <th>view_position</th>\n",
       "      <th>finding_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_index  follow-up_#  patient_age  patient_gender  view_position  \\\n",
       "0  00000001_000.png            0           58               0              0   \n",
       "1  00000001_001.png            1           58               0              0   \n",
       "2  00000001_002.png            2           58               0              0   \n",
       "\n",
       "   finding_labels  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/lung_disease_labels.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_index</th>\n",
       "      <th>follow-up_#</th>\n",
       "      <th>patient_age</th>\n",
       "      <th>patient_gender</th>\n",
       "      <th>view_position</th>\n",
       "      <th>finding_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_index  follow-up_#  patient_age  patient_gender  view_position  \\\n",
       "0  00000001_000.png            0           58               0              0   \n",
       "1  00000001_001.png            1           58               0              0   \n",
       "2  00000001_002.png            2           58               0              0   \n",
       "3  00000002_000.png            0           81               0              0   \n",
       "4  00000003_000.png            0           81               1              0   \n",
       "\n",
       "   finding_labels  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df = df[df[\"image_index\"].isin(image_files)]\n",
    "print(subset_df.shape)\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it's missing images, it's likely just from the faulty age data we removed. This is fine, let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def opencv_preprocessing(image_path, final_size=(224, 224)):\n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    image = cv2.equalizeHist(image)\n",
    "    \n",
    "    image = cv2.resize(image, final_size)\n",
    "    \n",
    "    # Optional: Clip pixel values to be in the valid range (0-255)\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    \n",
    "    # Convert from OpenCV image (NumPy array) to PIL image for Torch transformations\n",
    "    pil_image = Image.fromarray(image)\n",
    "    \n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def torch_preprocessing():\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),       # Apply random horizontal flip\n",
    "        transforms.RandomRotation(10),           # Apply random rotation of Â±10 degrees\n",
    "        transforms.ToTensor(),                   # Convert image to tensor\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize the pixel values\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, opencv_preprocess_fn, torch_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame containing image names and corresponding labels.\n",
    "            image_dir (str): Directory containing all images.\n",
    "            opencv_preprocess_fn (function): Function to apply OpenCV preprocessing.\n",
    "            torch_transform (function, optional): Torch transforms to be applied after OpenCV preprocessing.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir  # Single image directory\n",
    "        self.opencv_preprocess_fn = opencv_preprocess_fn\n",
    "        self.transform = torch_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is the length of the dataframe\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx]['image_index'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['finding_labels']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(\n",
    "    dataframe=subset_df, \n",
    "    image_dir=\"D:\\BigData\\images_001\\images\", \n",
    "    opencv_preprocess_fn=opencv_preprocessing,  # Use your preprocessing function here\n",
    "    torch_transform=torch_preprocessing()  # Use your Torch transforms here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_subset, test_subset = random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=8, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_subset, batch_size=8, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load one batch: 0.35 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Test loading one batch from train_loader\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time to load one batch: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RaviB\\anaconda3\\envs\\healthscan\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RaviB\\anaconda3\\envs\\healthscan\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1  # Remember we are starting with binary classification here for simply detecting if a disease is present or not\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, num_classes),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        batch_start_time = time.time()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                  f\"Batch [{i+1}/{len(train_loader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}, \"\n",
    "                  f\"Batch Time: {time.time() - batch_start_time:.2f}s\")\n",
    "            \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed, \"\n",
    "        f\"Average Loss: {epoch_loss:.4f}, \"\n",
    "        f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs.squeeze(), labels).item()\n",
    "            predicted = torch.round(torch.sigmoid(outputs.squeeze()))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "                print(f\"Validation Batch [{i+1}/{len(test_loader)}] processed\")\n",
    "            \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {loss.item():.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(test_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dirs, opencv_preprocess_fn, torch_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame containing image names and corresponding labels.\n",
    "            image_dirs (list of str): List of directories containing images.\n",
    "            opencv_preprocess_fn (function): Function to apply OpenCV preprocessing.\n",
    "            torch_transform (function, optional): Torch transforms to be applied after OpenCV preprocessing.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dirs = image_dirs  # List of directories containing images\n",
    "        self.opencv_preprocess_fn = opencv_preprocess_fn\n",
    "        self.transform = torch_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is the length of the dataframe\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def find_image_path(self, image_name):\n",
    "        # Search for the image in each directory\n",
    "        for image_dir in self.image_dirs:\n",
    "            image_path = os.path.join(image_dir, image_name)\n",
    "            if os.path.exists(image_path):\n",
    "                return image_path\n",
    "        raise FileNotFoundError(f\"Image {image_name} not found in any directory!\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image name and label from the dataframe\n",
    "        image_name = self.dataframe.iloc[idx]['image_index']  # Image file name\n",
    "        label = self.dataframe.iloc[idx]['finding_labels']  # Corresponding label\n",
    "\n",
    "        # Find the full image path by checking both directories\n",
    "        image_path = self.find_image_path(image_name)\n",
    "\n",
    "        # Apply OpenCV preprocessing to the image\n",
    "        image = self.opencv_preprocess_fn(image_path)\n",
    "\n",
    "        # Apply Torch transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load a pretrained ResNet model for binary or multi-label classification\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1  # Remember we are starting with binary classification here for simply detecting if a disease is present or not\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, num_classes),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dirs = [r\"D:\\BigData\\images_003\\images\", r\"D:\\BigData\\images_008\\images\"]\n",
    "image_dirs = [r\"D:\\BigData\\images_003\\images\"]\n",
    "\n",
    "train_dataset = ImageDataset(\n",
    "    dataframe=subset_df, \n",
    "    image_dirs=image_dirs, \n",
    "    opencv_preprocess_fn=opencv_preprocessing, \n",
    "    torch_transform=torch_preprocessing()\n",
    ")\n",
    "\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_subset, test_subset = random_split(train_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RaviB\\anaconda3\\envs\\healthscan\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RaviB\\anaconda3\\envs\\healthscan\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Get a single batch from the DataLoader\n",
    "data_iter = iter(train_loader)\n",
    "#images, labels = next(data_iter)  # Get the first batch of images and labels\n",
    "\n",
    "#images.is_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = images.cpu()\n",
    "#labels = labels.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first image in the batch and its corresponding label\n",
    "def show_image(image, label):\n",
    "    # Convert the tensor image to a NumPy array for visualization\n",
    "    image = image.permute(1, 2, 0).numpy()  # Convert from (C, H, W) to (H, W, C)\n",
    "    \n",
    "    # Undo any normalization, if necessary\n",
    "    image = (image * 0.5) + 0.5  # Assuming your normalization was (mean=[0.5], std=[0.5])\n",
    "    \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display the first few images in the batch\n",
    "for i in range(4):  # Display first 4 images\n",
    "    show_image(images[i], labels[i].item())  # Convert the label tensor to a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# Use trange to add a progress bar for epochs\n",
    "for epoch in trange(num_epochs, desc=\"Training Progress\"):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over batches with a progress bar\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "\n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move data to the GPU (if available)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Optionally, save the trained model\n",
    "torch.save(model.state_dict(), 'xray_classification_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Lists to store loss values\n",
    "train_losses = []\n",
    "\n",
    "num_epochs = 1  # Adjust the number of epochs based on your needs\n",
    "\n",
    "# Start the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move the data to the appropriate device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Store the loss value for this epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Plot the training loss\n",
    "    clear_output(wait=True)  # Clear the output in the notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.title(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('xray_classification_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Here we'll build a computer vision model to detect if a lung disease is present or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "PyTorch works better with classes, so first let's define a class to load in our data during training. Also, we'll just use the data from one folder for now to make things simple as the focus is more so on building a proof of concept user facing app at the moment, rather than the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the dataset class\n",
    "class LungDiseaseDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx]['image_index'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['finding_labels']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"../data/lung_disease_labels.csv\")\n",
    "img_dir = \"D:\\BigData\\images_005\\images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataframe has the file names and labels from all the images folders, but since we are just using one for now, we need to access only those - i.e. get the relevant subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_image_files(index_lst: list):\n",
    "    image_files = []\n",
    "\n",
    "    for i in index_lst:\n",
    "        image_dir = f\"D:\\BigData\\images_00{i}\\images\"\n",
    "        \n",
    "        image_files_for_one_folder = os.listdir(image_dir)\n",
    "        \n",
    "        image_files += image_files_for_one_folder\n",
    "        \n",
    "    return image_files\n",
    "\n",
    "image_files = get_image_files([5])\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can double check it worked here by inspecting the first few elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00009232_004.png',\n",
       " '00009232_005.png',\n",
       " '00009232_006.png',\n",
       " '00009232_007.png',\n",
       " '00009233_000.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df = df[df[\"image_index\"].isin(image_files)]\n",
    "subset_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from the previous notebook we want a ratio of around 1.16 in the binary target variable, to reflect the total dataset distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2070183182520415"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df[\"finding_labels\"].value_counts()[0] / subset_df[\"finding_labels\"].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Split the data into training and testing sets. The testing set here is just the validation set. Since we have plenty of other images in the other folders, we can use them for testing at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(subset_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need our transformations. The main thing to do here is resize the images so it's more manageble, but we can come back here and play with transformations later on too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = LungDiseaseDataset(train_df, img_dir, transform=transform)\n",
    "val_dataset = LungDiseaseDataset(val_df, img_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the number of workers must be zero to work depending on hardware resources - otherwise you'll get stuck in an endless runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just to make sure the DataLoader works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load one batch: 0.58 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Test loading one batch from train_loader\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time to load one batch: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get into model training. We'll use the resnet pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RaviB\\anaconda3\\envs\\healthscan\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RaviB\\anaconda3\\envs\\healthscan\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Batch [10/250], Loss: 0.5564, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [20/250], Loss: 0.7486, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [30/250], Loss: 0.6566, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [40/250], Loss: 0.7193, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [50/250], Loss: 0.6469, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [60/250], Loss: 0.6081, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [70/250], Loss: 0.6939, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [80/250], Loss: 0.6677, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [90/250], Loss: 0.7337, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [100/250], Loss: 0.7138, Batch Time: 0.20s\n",
      "Epoch [1/2], Batch [110/250], Loss: 0.6079, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [120/250], Loss: 0.5996, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [130/250], Loss: 0.6196, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [140/250], Loss: 0.6720, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [150/250], Loss: 0.7051, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [160/250], Loss: 0.6093, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [170/250], Loss: 0.6733, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [180/250], Loss: 0.5544, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [190/250], Loss: 0.7045, Batch Time: 0.19s\n",
      "Epoch [1/2], Batch [200/250], Loss: 0.7280, Batch Time: 0.18s\n",
      "Epoch [1/2], Batch [210/250], Loss: 0.5407, Batch Time: 0.18s\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        batch_start_time = time.time()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                  f\"Batch [{i+1}/{len(train_loader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}, \"\n",
    "                  f\"Batch Time: {time.time() - batch_start_time:.2f}s\")\n",
    "            \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed, \"\n",
    "        f\"Average Loss: {epoch_loss:.4f}, \"\n",
    "        f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs.squeeze(), labels).item()\n",
    "            predicted = torch.round(torch.sigmoid(outputs.squeeze()))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "                print(f\"Validation Batch [{i+1}/{len(val_loader)}] processed\")\n",
    "            \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {loss.item():.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
